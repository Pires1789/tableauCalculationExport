{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in this version:\n",
    "#removed parsing of xml to get all calculated fields and parameters as this can already be done with the doc api info\n",
    "#removed doc api loop that only went through some sheets, as this was missing out some calculations. Now all calcs and default fields should be extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import bs4 as bs\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import os, re, sys\n",
    "\n",
    "import win32com.client\n",
    "from pywintypes import com_error\n",
    "from os.path import isfile, join\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "from lxml import etree as ET\n",
    "\n",
    "import tableaudocumentapi\n",
    "from tableaudocumentapi import Workbook\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input folder - Find if there is a twbx or twb file in the folder\n",
    "- if there is a twbx, unzip it to create a twb, then work with this\n",
    "- if there's only a twb, work with this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_path = \"inputs\"\n",
    "output_path = \"outputs\"\n",
    "\n",
    "mypath = \"./{}\".format(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#only gets files and not directories within the inputs folder -https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory\n",
    "f = [f for f in os.listdir(mypath) if isfile(join(mypath, f))] \n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeSpecialCharFromStr(spstring):\n",
    "  \n",
    "    return ''.join(e for e in spstring if e.isalnum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [f for f in os.listdir(mypath) if isfile(join(mypath, f))] : \n",
    "   \n",
    "    if i[-5:] == '.twbx':\n",
    "        sp_packagedWorkbook = i[:len(i)-5]\n",
    "        print(sp_packagedWorkbook)\n",
    "        packagedWorkbook = removeSpecialCharFromStr(sp_packagedWorkbook)+'.twbx'\n",
    "        print(packagedWorkbook)\n",
    "        \n",
    "        old_file = join(input_path, sp_packagedWorkbook+'.twbx')\n",
    "        new_file = join(input_path, packagedWorkbook)\n",
    "        os.rename(old_file, new_file)\n",
    "        \n",
    "        with zipfile.ZipFile(input_path+\"/\"+packagedWorkbook, 'r') as zip_ref:\n",
    "            zip_ref.extractall(input_path+\"/\")\n",
    "    else:\n",
    "        packagedWorkbook = \"\"\n",
    "        \n",
    "for i in [f for f in os.listdir(mypath) if isfile(join(mypath, f))] :\n",
    "    \n",
    "    if i[-4:] == '.twb':\n",
    "        sp_unpackagedWorkbook = i[:len(i)-4]\n",
    "        unpackedWorkbook = removeSpecialCharFromStr(sp_unpackagedWorkbook)+'.twb' \n",
    "        \n",
    "        old_file = join(input_path, sp_unpackagedWorkbook+'.twb')\n",
    "        new_file = join(input_path, unpackedWorkbook)\n",
    "        os.rename(old_file, new_file)\n",
    "\n",
    "print('\\n')\n",
    "print('packaged workbook: ' + packagedWorkbook)\n",
    "print('unpackaged workbook: ' + unpackedWorkbook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableauFile = input_path+\"/\"+unpackedWorkbook\n",
    "tableauFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "packagedTableauFile = input_path+\"/\"+packagedWorkbook\n",
    "packagedTableauFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#substring to be used when naming the exported data, based on the packaged workbook as this is what we download from tableau server\n",
    "#we can rename the packaged workbook before running the script, giving more control to the naming of the extracted data\n",
    "\n",
    "tableau_name_substring = packagedWorkbook.replace(\".twbx\",\"\")[:30]\n",
    "tableau_name_substring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "packagedTableauFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#trying new way to see if more default fields are extracted\n",
    "sourceTWBX = Workbook(packagedTableauFile)\n",
    "\n",
    "collator = []\n",
    "calcID = []\n",
    "calcID2 = []\n",
    "calcNames = []\n",
    "\n",
    "c = 0\n",
    "\n",
    "worksheets = sourceTWBX.worksheets\n",
    "\n",
    "for worksheet in worksheets:\n",
    "    \n",
    "    for datasource in sourceTWBX.datasources:\n",
    "       \n",
    "        for count, field in enumerate(datasource.fields.values()):\n",
    "            \n",
    "            #if worksheet in field.worksheets: #removed this part so all fields are listed,as otherwise some fields were missed out\n",
    "                \n",
    "                dict_temp = {}\n",
    "                dict_temp['counter'] = c\n",
    "                dict_temp['worksheet'] = worksheet\n",
    "                dict_temp['datasource_name'] = datasource.name\n",
    "                dict_temp['field_WHOLE'] = field\n",
    "                dict_temp['field_name'] = field.name\n",
    "                dict_temp['field_caption'] = field.caption\n",
    "                dict_temp['field_calculation'] = field.calculation\n",
    "                dict_temp['field_id'] = field.id\n",
    "                dict_temp['field_datatype'] = field.datatype\n",
    "                \n",
    "                \n",
    "                if not(isinstance(field.calculation, type(None))):\n",
    "                    calcID.append(field.id)\n",
    "                    calcNames.append(field.name)\n",
    "                    \n",
    "                    f2 = (field.id).replace(']','')\n",
    "                    f2 = f2.replace('[', '')\n",
    "                    calcID2.append(f2)\n",
    "                \n",
    "                c = c + 1\n",
    "                \n",
    "                collator.append(dict_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "calcDict = dict(zip(calcID, calcNames))\n",
    "calcDict2 = dict(zip(calcID2, calcNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_to_friendly_names(formulaList,fieldToConvert, dictToUse):\n",
    "\n",
    "    for i in formulaList:\n",
    "        for tableauName, friendlyName in dictToUse.items():\n",
    "            try:\n",
    "                i[fieldToConvert] = (i[fieldToConvert]).replace(tableauName, friendlyName)\n",
    "            except:\n",
    "                a = 0\n",
    "       \n",
    "    return formulaList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "default_to_friendly_names(collator,'field_calculation',calcDict)\n",
    "\n",
    "df_fields_DocAPI = pd.DataFrame(collator)\n",
    "\n",
    "def f(row):\n",
    "    if row['field_calculation'] == None:\n",
    "        val = 'Datasource field'\n",
    "    else:\n",
    "        val = 'Calculated field'\n",
    "    return val\n",
    "\n",
    "df_fields_DocAPI['field_type'] = df_fields_DocAPI.apply(f, axis=1)\n",
    "\n",
    "df_fields_DocAPI.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_fields_DocAPI[colsToUse][(df_fields_DocAPI['field_type']!='Datasource field')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculated fields and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colsToUse = ['field_id', 'field_name', 'field_calculation', 'field_caption','field_datatype', 'datasource_name' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get parameters from doc api\n",
    "len_parameters = len(df_fields_DocAPI[colsToUse][(df_fields_DocAPI['field_type']!='Datasource field') & (df_fields_DocAPI['datasource_name']=='Parameters')].drop_duplicates())\n",
    "print('Parameter count: ' + str(len_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get calculated fields from doc api\n",
    "len_CalcFields = len(df_fields_DocAPI[colsToUse][(df_fields_DocAPI['field_type']!='Datasource field') & (df_fields_DocAPI['datasource_name']!='Parameters')].drop_duplicates())\n",
    "print('Calculated field count: ' + str(len_CalcFields))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfAPIcalcsAndParameters = df_fields_DocAPI[colsToUse][df_fields_DocAPI['field_type']!='Datasource field'].drop_duplicates().copy()\n",
    "dfAPIcalcsAndParameters['isParameter'] = np.where(dfAPIcalcsAndParameters['datasource_name']=='Parameters', 'yes', 'no')\n",
    "\n",
    "df = dfAPIcalcsAndParameters[['field_name', 'field_datatype', 'field_calculation','isParameter', 'field_id']].copy()\n",
    "df.columns = ['CalculationName', 'DataType', 'Formula', 'isParameter', 'RawName']\n",
    "\n",
    "df = df.sort_values(by=['isParameter','CalculationName'])\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All default fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default fields\n",
    "len_defaultFields = len(df_fields_DocAPI[colsToUse][df_fields_DocAPI['field_type']=='Datasource field'].drop_duplicates())\n",
    "print('Default field count: ' + str(len_defaultFields))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_defaultFields = df_fields_DocAPI[['field_id', 'field_caption','field_datatype', 'datasource_name' ]][df_fields_DocAPI['field_type'] == 'Datasource field'].drop_duplicates()\n",
    "\n",
    "df_defaultFields['prefOrder'] = np.where(df_defaultFields['field_caption'].isnull(), 0, 1)\n",
    "\n",
    "df_defaultFields['field_id2'] = df_defaultFields['field_id'].str.replace('[','')\n",
    "df_defaultFields['field_id2'] = df_defaultFields['field_id2'].str.replace(']','')\n",
    "\n",
    "df_defaultFields = df_defaultFields.sort_values(by = ['field_id2'])\n",
    "\n",
    "#https://stackoverflow.com/questions/63271050/use-drop-duplicates-in-pandas-df-but-choose-keep-column-based-on-a-preference-li\n",
    "preference_list=[1,0]\n",
    "\n",
    "df_defaultFields[\"prefOrder\"] = pd.Categorical(df_defaultFields[\"prefOrder\"], categories=preference_list, ordered=True)\n",
    "\n",
    "df_defaultFields = df_defaultFields.sort_values([\"field_id2\",\"prefOrder\"]).drop_duplicates(\"field_id2\")\n",
    "df_defaultFields = df_defaultFields.drop('prefOrder', axis=1)\n",
    "df_defaultFields = df_defaultFields.drop('field_id2', axis=1)\n",
    "df_defaultFields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sheet - all field dependencies, not just the explicitly used fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_sheetDependencies = df_fields_DocAPI.copy()\n",
    "\n",
    "df_sheetDependencies['prefOrder'] = np.where(df_sheetDependencies['field_caption'].isnull(), 0, 1)\n",
    "\n",
    "df_sheetDependencies['field_id2'] = df_sheetDependencies['field_id'].str.replace('[','')\n",
    "df_sheetDependencies['field_id2'] = df_sheetDependencies['field_id2'].str.replace(']','')\n",
    "\n",
    "preference_list=[1,0]\n",
    "\n",
    "df_sheetDependencies[\"prefOrder\"] = pd.Categorical(df_sheetDependencies[\"prefOrder\"], categories=preference_list, ordered=True)\n",
    "df_sheetDependencies = df_sheetDependencies.sort_values([\"field_id2\",\"prefOrder\"]).drop_duplicates(subset=[\"field_id2\", \"worksheet\"])\n",
    "df_sheetDependencies = df_sheetDependencies.drop('prefOrder', axis=1)\n",
    "df_sheetDependencies = df_sheetDependencies.drop('field_id2', axis=1)\n",
    "\n",
    "df_sheetDependencies = df_sheetDependencies.drop(columns=['counter', 'field_caption', 'field_WHOLE', 'field_calculation', 'field_id'])\n",
    "\n",
    "df_sheetDependencies = df_sheetDependencies[['worksheet', 'field_name', 'field_datatype', 'field_type', 'datasource_name']].sort_values(by = ['worksheet', 'field_type','datasource_name', 'field_name'])\n",
    "df_sheetDependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting all filters for all worksheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for worskheet in root.findall(\"./worksheets/worksheet\"):\n",
    "#     for filt in worskheet.findall('table/view/filter'):\n",
    "#         print(filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse(tableauFile)\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters_in_sheet = []\n",
    "context = []\n",
    "collatelist = []\n",
    "\n",
    "for worskheet in root.findall(\"./worksheets/worksheet\"):\n",
    "    \n",
    "    tempdict = {}\n",
    "    c = 0\n",
    "    \n",
    "    for filt in worskheet.findall('table/view/filter'):\n",
    "\n",
    "        calcfromfilter = filt.attrib['column']        \n",
    "        pat = '(?<=\\:)(.*?)(?=\\:)' \n",
    "        string_cleaned = calcfromfilter.split('].[')[1].replace(']','')\n",
    "        \n",
    "        tempdict['field'] = calcfromfilter\n",
    "        tempdict['formula'] = calcfromfilter\n",
    "        tempdict['counter'] = c\n",
    "        tempdict['sheetname'] = worskheet.attrib['name']\n",
    "        \n",
    "        try:\n",
    "            st1 = re.findall(pat,string_cleaned)[0]\n",
    "            tempdict['field'] = st1\n",
    "            tempdict['formula'] = st1\n",
    "            collatelist.append(tempdict)\n",
    "            \n",
    "        except:\n",
    "            st2 = string_cleaned.replace(':','')\n",
    "            tempdict['field'] = st2\n",
    "            tempdict['formula'] = st2\n",
    "            collatelist.append(tempdict)\n",
    "\n",
    "        try:\n",
    "            tempdict['context'] = filt.attrib['context']\n",
    "        except:\n",
    "            tempdict['context'] = 'False'\n",
    "           \n",
    "        c = c + 1\n",
    "        tempdict = {}\n",
    "    \n",
    "collatelist[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collatelist = default_to_friendly_names(collatelist, 'formula', calcDict2)\n",
    "collatelist[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    df1 = pd.DataFrame(collatelist)\n",
    "\n",
    "    df1 = df1[['sheetname', 'formula', 'context', 'field']]\n",
    "    df1.columns = ['Sheet Name', 'FilterField', 'Context filter', 'FilterField_RawName']\n",
    "\n",
    "    print(df1.head(2))\n",
    "except:\n",
    "    print('error with df1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting rows and cols for each sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "collecteddata = []\n",
    "\n",
    "for worksheet in root.findall(\"./worksheets/worksheet\"):\n",
    "\n",
    "    argumentstopass = ['rows', 'cols']\n",
    "    \n",
    "    for i in argumentstopass:   \n",
    "    \n",
    "        internaldict = {}\n",
    "\n",
    "        internaldict['sheetname'] = worksheet.attrib['name']\n",
    "        internaldict['type'] = i\n",
    "        \n",
    "        formulahere = worksheet.findall('table/'+i)[0].text\n",
    "        internaldict['formula'] = formulahere\n",
    "        \n",
    "        collecteddata.append(internaldict)\n",
    "    \n",
    "collecteddata[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in collecteddata:\n",
    "\n",
    "    try:\n",
    "        pattern = '\\:.*?\\:'\n",
    "        pat = '(?<=\\:)(.*?)(?=\\:)'\n",
    "\n",
    "        calculationsWithColon = re.findall(pattern,i['formula']) \n",
    "        calcsWithoutColon = []\n",
    "\n",
    "        for n in calculationsWithColon:\n",
    "            oneCalcWithoutColon = re.findall(pat,n)[0]\n",
    "\n",
    "            calcsWithoutColon.append(oneCalcWithoutColon)\n",
    "\n",
    "        i['extracted formulas'] = calcsWithoutColon\n",
    "        \n",
    "    except:\n",
    "        i['extracted formulas'] = []\n",
    "             \n",
    "    newcalcs = []\n",
    "    formulas_to_process = i['extracted formulas']\n",
    "    \n",
    "    for n in formulas_to_process:\n",
    "\n",
    "        for tableauName, friendlyName in calcDict2.items():\n",
    "            \n",
    "            n = n.replace(tableauName, friendlyName)\n",
    "        newcalcs.append(n)\n",
    "        \n",
    "    i['processed formulas'] = newcalcs\n",
    "\n",
    "collecteddata[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(collecteddata)\n",
    "df2 = df2.drop(columns=['formula', 'extracted formulas'])\n",
    "df2 = df2.pivot(index='sheetname', columns='type', values='processed formulas')\n",
    "df2 = df2.reset_index()\n",
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General workbook description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceTWBX = Workbook(packagedTableauFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_list = []\n",
    "\n",
    "for dash in sourceTWBX.dashboards:\n",
    "    dicti = {}\n",
    "    \n",
    "    dicti['type'] = 'dashboard'\n",
    "  #  print(format(dash))\n",
    "    dicti['name'] = format(dash)\n",
    "   \n",
    "    collate_list.append(dicti)\n",
    "    \n",
    "for data in sourceTWBX.datasources:\n",
    "    dicti = {}\n",
    "    \n",
    "    dicti['type'] = 'datasource'\n",
    "    dicti['name'] = format(data.name)\n",
    "   # print(format(data.name))\n",
    "   \n",
    "    collate_list.append(dicti)\n",
    "    \n",
    "for data in sourceTWBX.worksheets:\n",
    "    dicti = {}\n",
    "    \n",
    "    dicti['type'] = 'sheet'\n",
    "    dicti['name'] = format(data)\n",
    "   # print(format(data))\n",
    "    \n",
    "    collate_list.append(dicti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_workbookdec = pd.DataFrame(collate_list)\n",
    "df_workbookdec = df_workbookdec[['type', 'name']]\n",
    "df_workbookdec.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_workbookdec_counts = df_workbookdec.groupby(['type']).count().reset_index()\n",
    "df_workbookdec_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating an excel file from a df (so the excel rows/cols can be formatted), then turning the excel into a pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load env variable with full path to folder, as otherwise the pdf creation fails\n",
    "\n",
    "with open(\"archive/path_string.txt\", \"r\") as f:\n",
    "    os.environ[\"path_string\"] = f.read()\n",
    "    \n",
    "path_string = os.environ.get('path_string', 'Not Set')\n",
    "path_string = r\"{}\".format(path_string)    #must create literal ending in tableauCalculationExport\\{}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loading the file names and output locations for the excel and pdfs to be produced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_to_use = tableau_name_substring    \n",
    "\n",
    "newFileName = 'outputs\\{}'.format(name_to_use)\n",
    "excelName = newFileName + \".xlsx\"\n",
    "pdfName = newFileName + \".pdf\"\n",
    "print(pdfName)\n",
    "\n",
    "excel_path = path_string.format(excelName)\n",
    "path_to_pdf = path_string.format(pdfName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Functions to format the excel files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colors to be used in each sheet\n",
    "c1 = '#f4dfa4'\n",
    "c2 = '#ffc8b3'\n",
    "c3 = '#fff0b3'\n",
    "c4 = '#d5dfb9'\n",
    "c5 = '#d1c5d3'\n",
    "c6 = '#bfd9d7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mainCol(colNumber, color):\n",
    "    format_mainCol = workbook.add_format({'text_wrap': True, 'bold': True})\n",
    "    format_mainCol.set_align('vcenter')\n",
    "    format_mainCol.set_bg_color(color)\n",
    "    format_mainCol.set_border(1)\n",
    "    worksheet.set_column(colNumber,colNumber,20,format_mainCol)\n",
    "    return worksheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalCol(colNumber, colWidth):\n",
    "    format2 = workbook.add_format({'text_wrap': True})\n",
    "    format2.set_align('vcenter')\n",
    "    format2.set_border(1)\n",
    "    worksheet.set_column(colNumber,colNumber,colWidth,format2)\n",
    "    return worksheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creation of excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modify this part if you want to add more information/dfs to be saved as a separate sheet in excel\n",
    "\n",
    "dfs_to_use = [{'excelSheetTitle': 'Dashboard, datasource and sheet details', 'df_to_use':df_workbookdec, 'mainColWidth':'' , \n",
    "               'normalColWidth': [30], 'sheetName': 'GeneralDetails', 'footer': 'Data_1', 'papersize':9, 'color': c1} , \n",
    "              \n",
    "              {'excelSheetTitle': 'Overall counts of dashboards, datasources and sheets', 'df_to_use':df_workbookdec_counts, 'mainColWidth':'' , \n",
    "               'normalColWidth': [10], 'sheetName': 'GeneralCounts', 'footer': 'Data_2', 'papersize':9, 'color': c1},\n",
    "              \n",
    "              {'excelSheetTitle': 'Default fields from all datasources', 'df_to_use':df_defaultFields, 'mainColWidth':'' , \n",
    "               'normalColWidth': [20,20,40], 'sheetName': 'DefaultFields', 'footer': 'Data_3', 'papersize':9, 'color': c2},\n",
    "              \n",
    "              {'excelSheetTitle': 'Calculated fields and parameters', 'df_to_use':df, 'mainColWidth':'' , \n",
    "               'normalColWidth': [10,50,10,20], 'sheetName': 'CalculatedFields', 'footer': 'Data_4', 'papersize':9, 'color': c3},\n",
    "              \n",
    "              {'excelSheetTitle': 'Filters used in each sheet', 'df_to_use':df1, 'mainColWidth':'' , \n",
    "               'normalColWidth': [20,20,40], 'sheetName': 'Filters', 'footer': 'Data_5', 'papersize':9, 'color': c4},\n",
    "              \n",
    "              {'excelSheetTitle': 'Metrics used in Columns and Rows, for each sheet', 'df_to_use':df2, 'mainColWidth':'' , \n",
    "               'normalColWidth': [30,40], 'sheetName': 'RowsAndCols', 'footer': 'Data_6', 'papersize':9, 'color': c5},\n",
    "              \n",
    "              {'excelSheetTitle': 'Sheet dependencies on default fields, calculated fields and parameters', 'df_to_use':df_sheetDependencies, 'mainColWidth':'' , \n",
    "               'normalColWidth': [30,15,25,30], 'sheetName': 'SheetDependencies', 'footer': 'Data_7', 'papersize':8, 'color': c6}\n",
    "             ]\n",
    "\n",
    "#papersize: a3 = 8, a4 = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(excelName, engine = 'xlsxwriter')\n",
    "\n",
    "#code to create each sheet in excel, with the specified df and formatting each sheet as per requirements\n",
    "#also adds a header and footer to each sheet\n",
    "#all the info to be replaced below (ie. for each df) comes form the dfs_to_use list of dictionaries\n",
    "\n",
    "for x in dfs_to_use:\n",
    "    excelSheetTitle = x['excelSheetTitle']\n",
    "    df_to_use = x['df_to_use']\n",
    "    normalColWidth = x['normalColWidth']\n",
    "    sheetName = x['sheetName']\n",
    "    papersize = x['papersize']\n",
    "    footer = x['footer']\n",
    "    color = x['color']\n",
    "\n",
    "    df_to_use.to_excel(writer, sheet_name = sheetName, index=False)\n",
    "    \n",
    "    workbook=writer.book\n",
    "    worksheet = writer.sheets[sheetName]\n",
    "\n",
    "    worksheet = mainCol(0, color)\n",
    "    \n",
    "    ws = 1\n",
    "    for i in normalColWidth:\n",
    "        worksheet = normalCol(ws,i)\n",
    "        ws = ws + 1\n",
    "\n",
    "    worksheet.set_paper(papersize) # a4\n",
    "    worksheet.fit_to_pages(1,0)    # fit to 1 page wide, n long\n",
    "    worksheet.repeat_rows(0)       # repeat the first row\n",
    "    \n",
    "    header_x = '&C&\"Arial,Bold\"&10{}'.format(excelSheetTitle)\n",
    "    footer_x = '&L{}&CPage &P of &N'.format(footer)\n",
    "\n",
    "    worksheet.set_header(header_x)\n",
    "    worksheet.set_footer(footer_x)\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creation of pdf from excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this creates an index to list each excel sheet, based on the number of sheets that were created before\n",
    "\n",
    "for_ws_index_list = []\n",
    "for i in range(len(dfs_to_use)):\n",
    "    for_ws_index_list.append(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel = win32com.client.Dispatch(\"Excel.Application\")\n",
    "excel.Visible = False\n",
    "\n",
    "wb = excel.Workbooks.Open(excel_path)\n",
    "\n",
    "#print all the excel sheets into a single pdf\n",
    "ws_index_list = for_ws_index_list\n",
    "wb.Worksheets(ws_index_list).Select()\n",
    "wb.ActiveSheet.ExportAsFixedFormat(0, path_to_pdf)\n",
    "wb.Close()\n",
    "excel.Quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
